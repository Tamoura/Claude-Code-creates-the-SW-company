# New Feature Workflow Task Graph Template
# Placeholders: {PRODUCT}, {FEATURE}, {FEATURE_ID}, {DESCRIPTION}, {TIMESTAMP}
# Traceability Placeholders: {STORY_IDS}, {REQUIREMENT_IDS}, {EPIC_ID}, {SPRINT}
#
# TRACEABILITY RULES (Constitution Article VI):
#   - Every task MUST populate story_ids and requirement_ids
#   - Orchestrator fills these from the spec/PRD when instantiating
#   - Commits MUST include [US-XX] or [FR-XXX] in the message
#   - Tests MUST reference acceptance criteria IDs in test names
#   - E2E tests organized by story: e2e/tests/stories/{story-id}/
#   - PR description MUST list implemented story/requirement IDs

metadata:
  product: "{PRODUCT}"
  feature: "{FEATURE}"
  feature_id: "{FEATURE_ID}"
  version: "2.0.0"
  workflow_type: "new-feature"
  created_at: "{TIMESTAMP}"
  updated_at: "{TIMESTAMP}"
  traceability:
    brd_ref: "products/{PRODUCT}/docs/PRD.md"
    spec_ref: "products/{PRODUCT}/docs/specs/{FEATURE_ID}.md"
    story_ids: ["{STORY_IDS}"]
    requirement_ids: ["{REQUIREMENT_IDS}"]
    epic: "{EPIC_ID}"
    sprint: "{SPRINT}"

tasks:
  # ============================================================================
  # PHASE 1: DESIGN
  # ============================================================================

  - id: "DESIGN-{FEATURE_ID}"
    name: "Design {FEATURE}"
    description: |
      Review the feature request: {DESCRIPTION}

      Tasks:
      - Review existing PRD and architecture
      - Design API changes (if any)
      - Design UI changes (if any)
      - Identify affected components
      - Create feature specification document
      - Map new/changed endpoints to requirement IDs
    agent: "architect"
    depends_on: []
    story_ids: ["{STORY_IDS}"]
    requirement_ids: ["{REQUIREMENT_IDS}"]
    epic: "{EPIC_ID}"
    produces:
      - name: "Feature Design"
        type: "document"
        path: "products/{PRODUCT}/docs/features/{FEATURE_ID}-{FEATURE}.md"
    context_output: ""
    parallel_ok: false
    checkpoint: true
    priority: "high"
    estimated_time_minutes: 60
    acceptance_criteria:
      - "Feature specification document created"
      - "API changes documented with FR-XXX / US-XX linkage"
      - "UI changes documented (if applicable)"
      - "Affected components identified"
      - "No conflicts with existing architecture"
      - "Traceability: every change mapped to a story/requirement"
    status: "pending"

  # ============================================================================
  # PHASE 2: IMPLEMENTATION (Parallel)
  # ============================================================================

  # --- Backend TDD Split ---

  - id: "BACKEND-TESTS-{FEATURE_ID}"
    name: "Write Failing Backend Tests for {FEATURE}"
    description: |
      TDD RED phase — write failing tests for backend changes:
      - Read feature design and acceptance criteria
      - Write unit tests for new API endpoints
      - Write integration tests for request/response flows
      - Write database state verification tests
      - Test names include [US-XX][AC-X] IDs
      - Run tests — they MUST FAIL (no implementation yet)
      - Commit: test(scope): add failing tests for {FEATURE} [US-XX]
      DO NOT write any implementation code!
    agent: "backend-engineer"
    depends_on: ["DESIGN-{FEATURE_ID}"]
    story_ids: ["{STORY_IDS}"]
    requirement_ids: ["{REQUIREMENT_IDS}"]
    epic: "{EPIC_ID}"
    consumes:
      - name: "Feature Design"
        required_from_task: "DESIGN-{FEATURE_ID}"
    produces:
      - name: "Backend Tests"
        type: "directory"
        path: "products/{PRODUCT}/apps/api/tests"
    context_output: ""
    parallel_ok: true
    checkpoint: false
    priority: "high"
    estimated_time_minutes: 60
    acceptance_criteria:
      - "Unit tests written for all new endpoints"
      - "Integration tests written for request/response flows"
      - "All new tests FAIL when run (no implementation yet)"
      - "Test names include [US-XX][AC-X] IDs"
      - "Tests committed to branch"
    status: "pending"

  - id: "BACKEND-IMPL-{FEATURE_ID}"
    name: "Implement Backend for {FEATURE}"
    description: |
      TDD GREEN phase — make failing tests pass:
      - Write the simplest code to make all tests pass
      - Implement API endpoints, database schema changes, services
      - Run ALL tests — they MUST all pass
      - Commits include [US-XX][FR-XXX] IDs
      - Do NOT modify test files
      After green: REFACTOR if needed (keep tests passing)
    agent: "backend-engineer"
    depends_on: ["BACKEND-TESTS-{FEATURE_ID}"]
    story_ids: ["{STORY_IDS}"]
    requirement_ids: ["{REQUIREMENT_IDS}"]
    epic: "{EPIC_ID}"
    consumes:
      - name: "Backend Tests"
        required_from_task: "BACKEND-TESTS-{FEATURE_ID}"
      - name: "Feature Design"
        required_from_task: "DESIGN-{FEATURE_ID}"
    produces:
      - name: "Backend Implementation"
        type: "directory"
        path: "products/{PRODUCT}/apps/api/src"
    context_output: ""
    parallel_ok: true
    checkpoint: false
    priority: "high"
    estimated_time_minutes: 90
    acceptance_criteria:
      - "All new tests now pass"
      - "All existing tests still pass (no regressions)"
      - "Database migrations created (if needed)"
      - "Test coverage >= 80%"
    status: "pending"

  # --- Frontend TDD Split ---

  - id: "FRONTEND-TESTS-{FEATURE_ID}"
    name: "Write Failing Frontend Tests for {FEATURE}"
    description: |
      TDD RED phase — write failing tests for frontend changes:
      - Read feature design and acceptance criteria
      - Write component tests for new UI elements
      - Write integration tests for API connections
      - Test names include [US-XX][AC-X] IDs
      - Run tests — they MUST FAIL (no implementation yet)
      - Commit: test(scope): add failing tests for {FEATURE} [US-XX]
      DO NOT write any implementation code!
    agent: "frontend-engineer"
    depends_on: ["DESIGN-{FEATURE_ID}"]
    story_ids: ["{STORY_IDS}"]
    requirement_ids: ["{REQUIREMENT_IDS}"]
    epic: "{EPIC_ID}"
    consumes:
      - name: "Feature Design"
        required_from_task: "DESIGN-{FEATURE_ID}"
    produces:
      - name: "Frontend Tests"
        type: "directory"
        path: "products/{PRODUCT}/apps/web/tests"
    context_output: ""
    parallel_ok: true
    checkpoint: false
    priority: "high"
    estimated_time_minutes: 45
    acceptance_criteria:
      - "Component tests written for new UI elements"
      - "All new tests FAIL when run (no implementation yet)"
      - "Test names include [US-XX][AC-X] IDs"
      - "Tests committed to branch"
    status: "pending"

  - id: "FRONTEND-IMPL-{FEATURE_ID}"
    name: "Implement Frontend for {FEATURE}"
    description: |
      TDD GREEN phase — make failing tests pass:
      - Implement UI components, pages, API integration
      - Ensure responsive design
      - Run ALL tests — they MUST all pass
      - Commits include [US-XX][FR-XXX] IDs
      - Do NOT modify test files
      After green: REFACTOR if needed (keep tests passing)
    agent: "frontend-engineer"
    depends_on: ["FRONTEND-TESTS-{FEATURE_ID}"]
    story_ids: ["{STORY_IDS}"]
    requirement_ids: ["{REQUIREMENT_IDS}"]
    epic: "{EPIC_ID}"
    consumes:
      - name: "Frontend Tests"
        required_from_task: "FRONTEND-TESTS-{FEATURE_ID}"
      - name: "Feature Design"
        required_from_task: "DESIGN-{FEATURE_ID}"
    produces:
      - name: "Frontend Implementation"
        type: "directory"
        path: "products/{PRODUCT}/apps/web/src"
    context_output: ""
    parallel_ok: true
    checkpoint: false
    priority: "high"
    estimated_time_minutes: 90
    acceptance_criteria:
      - "UI components implemented"
      - "API integration complete"
      - "Responsive design verified"
      - "All tests passing"
      - "No console errors"
    status: "pending"

  # ============================================================================
  # PHASE 3: TESTING & QUALITY
  # ============================================================================

  - id: "QA-{FEATURE_ID}"
    name: "Test {FEATURE}"
    description: |
      Comprehensive testing for {FEATURE}:
      - Write E2E tests for new functionality
      - Organize E2E tests by story: e2e/tests/stories/{story-id}/
      - Test descriptions include [US-XX][AC-X] IDs
      - Run full test suite
      - Verify visual appearance
      - Check for regressions
      - Run Testing Gate checklist
      - Generate requirement coverage report
    agent: "qa-engineer"
    depends_on: ["BACKEND-IMPL-{FEATURE_ID}", "FRONTEND-IMPL-{FEATURE_ID}"]
    story_ids: ["{STORY_IDS}"]
    requirement_ids: ["{REQUIREMENT_IDS}"]
    epic: "{EPIC_ID}"
    consumes:
      - name: "Backend Implementation"
        required_from_task: "BACKEND-IMPL-{FEATURE_ID}"
      - name: "Frontend Implementation"
        required_from_task: "FRONTEND-IMPL-{FEATURE_ID}"
    produces:
      - name: "E2E Tests"
        type: "directory"
        path: "products/{PRODUCT}/e2e/tests/{FEATURE_ID}"
      - name: "Test Report"
        type: "document"
        path: "products/{PRODUCT}/docs/test-reports/{FEATURE_ID}-{FEATURE}.md"
    context_output: ""
    parallel_ok: false
    checkpoint: false
    priority: "critical"
    estimated_time_minutes: 60
    acceptance_criteria:
      - "E2E tests written for new functionality"
      - "All unit tests passing"
      - "All E2E tests passing"
      - "No visual regressions"
      - "No console errors"
      - "Coverage >= 80%"
    status: "pending"

  - id: "DOCS-{FEATURE_ID}"
    name: "Update Documentation for {FEATURE}"
    description: |
      Update documentation:
      - Update API documentation
      - Update user guide (if applicable)
      - Update README if needed
    agent: "technical-writer"
    depends_on: ["BACKEND-IMPL-{FEATURE_ID}", "FRONTEND-IMPL-{FEATURE_ID}"]
    produces:
      - name: "Updated Docs"
        type: "document"
        path: "products/{PRODUCT}/docs/API.md"
    context_output: ""
    parallel_ok: true
    checkpoint: false
    priority: "normal"
    estimated_time_minutes: 30
    acceptance_criteria:
      - "API documentation updated"
      - "User-facing changes documented"
    status: "pending"

  # ============================================================================
  # PHASE 4: REVIEW
  # ============================================================================

  - id: "GATE-TESTING-{FEATURE_ID}"
    name: "Run Testing Gate for {FEATURE}"
    description: |
      Execute Testing Gate before CEO review:
      - Run: .claude/scripts/testing-gate-checklist.sh {PRODUCT}
      - Verify all checks pass
      - Generate test report
    agent: "qa-engineer"
    depends_on: ["QA-{FEATURE_ID}", "DOCS-{FEATURE_ID}"]
    produces:
      - name: "Testing Gate Report"
        type: "document"
        path: "products/{PRODUCT}/docs/quality-reports/testing-gate-{FEATURE_ID}.md"
    context_output: ""
    parallel_ok: false
    checkpoint: false
    priority: "critical"
    estimated_time_minutes: 30
    acceptance_criteria:
      - "Testing Gate PASS"
      - "All checks green"
    status: "pending"

  - id: "CHECKPOINT-{FEATURE_ID}"
    name: "Feature Complete - CEO Review"
    description: |
      {FEATURE} is complete and tested. Ready for CEO review:
      
      - Backend implementation complete
      - Frontend implementation complete
      - All tests passing
      - Documentation updated
      - Testing Gate PASSED
      
      CEO can now review and approve the feature.
    agent: "orchestrator"
    depends_on: ["GATE-TESTING-{FEATURE_ID}"]
    parallel_ok: false
    checkpoint: true
    priority: "critical"
    estimated_time_minutes: 0
    status: "pending"

# Execution estimates:
# - Sequential time: ~420 minutes (~7 hours)
# - Parallel optimized: ~270 minutes (~4.5 hours)
# - Savings from parallelization: ~36%
