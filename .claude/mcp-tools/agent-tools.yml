# Agent-Specific MCP Tools Configuration
# Phase 3 Enhancement: Specialized tools per agent type
#
# ╔═══════════════════════════════════════════════════════════════════════════╗
# ║  STATUS: FUTURE / ASPIRATIONAL                                            ║
# ║                                                                           ║
# ║  These MCP tools are PLANNED but NOT YET IMPLEMENTED.                    ║
# ║  Do NOT reference these tools in agent prompts until implemented.        ║
# ║                                                                           ║
# ║  Current agents should use standard Claude Code capabilities:            ║
# ║  - File reading/writing                                                  ║
# ║  - Shell command execution                                               ║
# ║  - Git operations                                                        ║
# ║  - Web browsing (for research)                                          ║
# ╚═══════════════════════════════════════════════════════════════════════════╝

version: "1.0.0"
updated_at: "2026-01-26T16:00:00Z"
status: "planned"  # NOT "active" - tools are not yet implemented

# =============================================================================
# BACKEND ENGINEER TOOLS (PLANNED)
# =============================================================================

backend-engineer:
  status: "planned"  # NOT IMPLEMENTED YET
  description: "Specialized tools for backend API development (FUTURE)"

  tools:
    # Database query analyzer
    - name: "db-query-analyzer"
      mcp_server: "database-tools"
      commands:
        - explain_query      # EXPLAIN ANALYZE for query optimization
        - suggest_index      # Suggest indices based on query patterns
        - check_n_plus_one   # Detect N+1 query problems

    # API contract validator
    - name: "api-validator"
      mcp_server: "api-tools"
      commands:
        - validate_openapi   # Validate OpenAPI spec
        - check_breaking     # Check for breaking API changes
        - generate_client    # Generate API client code

    # Load testing
    - name: "load-tester"
      mcp_server: "performance-tools"
      commands:
        - run_benchmark      # Run API load test
        - analyze_bottleneck # Find performance bottlenecks
        - suggest_caching    # Recommend caching strategy

    # Security scanner
    - name: "security-scanner"
      mcp_server: "security-tools"
      commands:
        - scan_sql_injection  # Check for SQL injection
        - scan_auth           # Verify authentication patterns
        - check_rate_limits   # Ensure rate limiting present

  # When to use
  use_when:
    - task_type: "api-implementation"
    - task_type: "database-design"
    - task_type: "performance-optimization"

  # Example usage
  example: |
    Backend Engineer implements new API endpoint:

    1. Write implementation
    2. Use db-query-analyzer to check query performance
    3. Use api-validator to verify OpenAPI spec
    4. Use security-scanner to check for vulnerabilities
    5. Use load-tester to benchmark performance
    6. Report results in AgentMessage

# =============================================================================
# FRONTEND ENGINEER TOOLS
# =============================================================================

frontend-engineer:
  description: "Specialized tools for UI development"

  tools:
    # Component analyzer
    - name: "component-analyzer"
      mcp_server: "react-tools"
      commands:
        - find_unused_props    # Detect unused component props
        - check_re_renders     # Find unnecessary re-renders
        - suggest_memo         # Recommend React.memo usage
        - analyze_bundle       # Component contribution to bundle

    # Accessibility checker
    - name: "a11y-checker"
      mcp_server: "accessibility-tools"
      commands:
        - check_aria           # Verify ARIA labels
        - check_contrast       # Color contrast ratios
        - check_keyboard_nav   # Keyboard navigation
        - run_axe             # Run axe-core accessibility tests

    # Bundle analyzer
    - name: "bundle-analyzer"
      mcp_server: "build-tools"
      commands:
        - analyze_size         # Bundle size breakdown
        - find_duplicates      # Find duplicate dependencies
        - suggest_code_split   # Recommend code-splitting
        - check_tree_shaking   # Verify tree-shaking working

    # Visual regression
    - name: "visual-diff"
      mcp_server: "testing-tools"
      commands:
        - capture_screenshot   # Capture component screenshot
        - compare_baseline     # Compare with baseline
        - approve_changes      # Approve visual changes

    # CSS analyzer
    - name: "css-analyzer"
      mcp_server: "style-tools"
      commands:
        - find_unused_css      # Unused CSS classes
        - check_specificity    # CSS specificity issues
        - optimize_tailwind    # Tailwind optimization

  use_when:
    - task_type: "ui-implementation"
    - task_type: "component-development"
    - task_type: "styling"
    - task_type: "performance-optimization"

  example: |
    Frontend Engineer implements new component:

    1. Write component code
    2. Use a11y-checker to verify accessibility
    3. Use component-analyzer to check for issues
    4. Use bundle-analyzer to verify size impact
    5. Use visual-diff to capture screenshot
    6. Report results

# =============================================================================
# QA ENGINEER TOOLS
# =============================================================================

qa-engineer:
  description: "Specialized tools for testing and quality assurance"

  tools:
    # Test coverage reporter
    - name: "coverage-reporter"
      mcp_server: "testing-tools"
      commands:
        - coverage_summary     # Coverage summary
        - uncovered_lines      # Show uncovered code
        - suggest_tests        # Suggest test cases for uncovered code

    # Visual regression tool
    - name: "visual-regression"
      mcp_server: "testing-tools"
      commands:
        - run_visual_tests     # Run all visual tests
        - update_baselines     # Update baseline screenshots
        - report_differences   # Report visual differences

    # Performance profiler
    - name: "perf-profiler"
      mcp_server: "performance-tools"
      commands:
        - profile_page_load    # Profile page load time
        - profile_interactions # Profile user interactions
        - lighthouse_audit     # Run Lighthouse audit
        - suggest_optimizations # Performance suggestions

    # Test data generator
    - name: "test-data-gen"
      mcp_server: "data-tools"
      commands:
        - generate_fixtures    # Generate test fixtures
        - seed_database        # Seed test database
        - cleanup_test_data    # Clean up after tests

    # Flaky test detector
    - name: "flaky-detector"
      mcp_server: "testing-tools"
      commands:
        - run_multiple_times   # Run test N times
        - analyze_flakiness    # Analyze failure patterns
        - suggest_fix          # Suggest flakiness fix

  use_when:
    - task_type: "testing"
    - task_type: "quality-assurance"
    - task_type: "test-automation"

  example: |
    QA Engineer runs Testing Gate:

    1. Run all tests
    2. Use coverage-reporter to verify coverage >= 80%
    3. Use visual-regression for UI tests
    4. Use perf-profiler for Lighthouse scores
    5. Use flaky-detector if any tests flaked
    6. Report comprehensive results

# =============================================================================
# DEVOPS ENGINEER TOOLS
# =============================================================================

devops-engineer:
  description: "Specialized tools for infrastructure and deployment"

  tools:
    # Infrastructure validator
    - name: "infra-validator"
      mcp_server: "infrastructure-tools"
      commands:
        - validate_terraform   # Validate Terraform/IaC
        - check_security       # Security best practices
        - cost_estimate        # Estimate infrastructure cost

    # Container scanner
    - name: "container-scanner"
      mcp_server: "docker-tools"
      commands:
        - scan_vulnerabilities # Scan Docker image for vulnerabilities
        - optimize_layers      # Optimize Docker layers
        - check_best_practices # Docker best practices

    # Deployment validator
    - name: "deploy-validator"
      mcp_server: "deployment-tools"
      commands:
        - dry_run              # Simulate deployment
        - check_rollback       # Verify rollback works
        - validate_health      # Check health checks configured

    # Monitoring setup
    - name: "monitoring-setup"
      mcp_server: "observability-tools"
      commands:
        - verify_logging       # Check logging configured
        - verify_metrics       # Check metrics collection
        - verify_alerts        # Check alert rules configured
        - verify_tracing       # Check distributed tracing

  use_when:
    - task_type: "infrastructure"
    - task_type: "deployment"
    - task_type: "ci-cd"

  example: |
    DevOps Engineer sets up infrastructure:

    1. Write Terraform/Docker configs
    2. Use infra-validator to validate
    3. Use container-scanner on Docker images
    4. Use deploy-validator to test deployment
    5. Use monitoring-setup to verify observability
    6. Report infrastructure status

# =============================================================================
# ARCHITECT TOOLS
# =============================================================================

architect:
  description: "Specialized tools for system design and architecture"

  tools:
    # Architecture diagram generator
    - name: "diagram-generator"
      mcp_server: "architecture-tools"
      commands:
        - generate_c4          # Generate C4 diagrams
        - generate_sequence    # Generate sequence diagrams
        - generate_erd         # Generate ERD from schema

    # Dependency analyzer
    - name: "dependency-analyzer"
      mcp_server: "analysis-tools"
      commands:
        - analyze_coupling     # Measure coupling
        - find_cycles          # Find circular dependencies
        - suggest_boundaries   # Suggest module boundaries

    # API design linter
    - name: "api-linter"
      mcp_server: "api-tools"
      commands:
        - lint_rest_api        # REST API best practices
        - check_consistency    # API consistency
        - suggest_versioning   # API versioning strategy

    # Performance estimator
    - name: "perf-estimator"
      mcp_server: "performance-tools"
      commands:
        - estimate_latency     # Estimate API latency
        - estimate_throughput  # Estimate throughput
        - suggest_scaling      # Scaling recommendations

  use_when:
    - task_type: "architecture"
    - task_type: "system-design"
    - task_type: "api-contract"

  example: |
    Architect designs new system:

    1. Create architecture document
    2. Use diagram-generator for visuals
    3. Use dependency-analyzer to check coupling
    4. Use api-linter to verify API design
    5. Use perf-estimator for scalability
    6. Report architecture with diagrams

# =============================================================================
# PRODUCT MANAGER TOOLS
# =============================================================================

product-manager:
  description: "Specialized tools for product requirements"

  tools:
    # Requirements analyzer
    - name: "requirements-analyzer"
      mcp_server: "product-tools"
      commands:
        - check_completeness   # Check PRD completeness
        - find_ambiguities     # Find ambiguous requirements
        - suggest_metrics      # Suggest success metrics

    # User story validator
    - name: "story-validator"
      mcp_server: "product-tools"
      commands:
        - validate_format      # Check user story format
        - check_testability    # Ensure testable criteria
        - suggest_acceptance   # Suggest acceptance criteria

    # Market research
    - name: "market-research"
      mcp_server: "research-tools"
      commands:
        - search_competitors   # Find competitor products
        - analyze_features     # Analyze competitor features
        - find_opensource      # Find relevant open source projects

  use_when:
    - task_type: "prd-creation"
    - task_type: "requirements"

  example: |
    Product Manager creates PRD:

    1. Write initial PRD
    2. Use market-research to find competitors
    3. Use requirements-analyzer to check completeness
    4. Use story-validator to verify user stories
    5. Report comprehensive PRD

# =============================================================================
# SUPPORT ENGINEER TOOLS
# =============================================================================

support-engineer:
  description: "Specialized tools for bug triage and support"

  tools:
    # Log analyzer
    - name: "log-analyzer"
      mcp_server: "debugging-tools"
      commands:
        - search_errors        # Search error logs
        - find_patterns        # Find error patterns
        - correlate_events     # Correlate related events

    # Bug triager
    - name: "bug-triager"
      mcp_server: "debugging-tools"
      commands:
        - suggest_severity     # Suggest bug severity
        - suggest_component    # Identify affected component
        - find_similar_bugs    # Find similar past bugs

    # Reproduction helper
    - name: "repro-helper"
      mcp_server: "testing-tools"
      commands:
        - generate_test_case   # Generate test case from bug report
        - capture_environment  # Capture environment details
        - create_minimal_repro # Create minimal reproduction

  use_when:
    - task_type: "bug-triage"
    - task_type: "issue-investigation"

  example: |
    Support Engineer triages bug:

    1. Read bug report
    2. Use log-analyzer to find error logs
    3. Use bug-triager to assess severity
    4. Use repro-helper to create test case
    5. Report findings with reproduction steps

# =============================================================================
# MCP SERVER IMPLEMENTATIONS
# =============================================================================

mcp_servers:
  # Note: These are placeholders - actual MCP servers would need to be
  # implemented and configured separately

  database-tools:
    description: "Database analysis and optimization"
    implementation: "custom"
    config_path: ".claude/mcp-servers/database-tools/config.json"

  api-tools:
    description: "API validation and generation"
    implementation: "custom"
    config_path: ".claude/mcp-servers/api-tools/config.json"

  performance-tools:
    description: "Performance benchmarking and profiling"
    implementation: "custom"
    config_path: ".claude/mcp-servers/performance-tools/config.json"

  security-tools:
    description: "Security scanning and validation"
    implementation: "custom"
    config_path: ".claude/mcp-servers/security-tools/config.json"

  react-tools:
    description: "React-specific analysis"
    implementation: "custom"
    config_path: ".claude/mcp-servers/react-tools/config.json"

  accessibility-tools:
    description: "Accessibility testing"
    implementation: "axe-core-mcp"  # Could use existing tool
    config_path: ".claude/mcp-servers/accessibility-tools/config.json"

  testing-tools:
    description: "Test automation and analysis"
    implementation: "custom"
    config_path: ".claude/mcp-servers/testing-tools/config.json"

  infrastructure-tools:
    description: "Infrastructure as Code tools"
    implementation: "terraform-mcp"  # Could use existing tool
    config_path: ".claude/mcp-servers/infrastructure-tools/config.json"

# =============================================================================
# USAGE NOTES
# =============================================================================

usage_notes:
  orchestrator:
    - "When invoking agent, include relevant tools in allowed_tools parameter"
    - "Example: Task(allowed_tools=['database-tools.*', 'api-tools.*'])"

  agents:
    - "Agents should use tools proactively when appropriate"
    - "Example: Backend engineer automatically runs db-query-analyzer on slow queries"
    - "Tools results included in AgentMessage for audit trail"

  benefits:
    - "Faster development (no manual analysis)"
    - "Higher quality (automated checks)"
    - "Consistent practices (tools enforce standards)"
    - "Knowledge capture (tool usage in memory)"
